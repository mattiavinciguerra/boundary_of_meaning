{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bdf348d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dade6d5b",
   "metadata": {},
   "source": [
    "### Load dataset and count words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90fa5dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"../1-dataset/VUAMC_sentences_labeled.csv\"\n",
    "data = pd.read_csv(dataset_path)\n",
    "sentences = data[\"sentence\"].tolist()\n",
    "metaphors = data[\"metaphors\"].tolist()\n",
    "metaphors = [set(m.strip().lower() for m in mlist.split(\";\")) if isinstance(mlist, str) else set() for mlist in metaphors]\n",
    "\n",
    "metaphor_counts = defaultdict(int)\n",
    "literal_counts = defaultdict(int)\n",
    "\n",
    "for sentence, sentence_metaphors in zip(sentences, metaphors):\n",
    "    words = re.findall(r\"\\w+\", sentence.lower())\n",
    "    for word in words:\n",
    "        if word in sentence_metaphors:\n",
    "            metaphor_counts[word] += 1\n",
    "        else:\n",
    "            literal_counts[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed694181",
   "metadata": {},
   "source": [
    "### Filter words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acaeb194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected words: {'given', 'long', 'make', 'go', 'take', 'see', 'bit', 'give', 'found', 'put', 'way', 'back', 'high', 'get', 'next', 'came', 'got', 'come'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mattia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "top_words = set(word for word in metaphor_counts if metaphor_counts[word] >= 40 and literal_counts[word] >= 40)\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "stopwords_set = set(stopwords.words(\"english\"))\n",
    "top_words -= stopwords_set\n",
    "\n",
    "print(f\"Selected words: {top_words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a740e574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To find the word's token (or tokens)\n",
    "def get_token_indices(word, all_tokens, tokenizer):\n",
    "    word_tokens = tokenizer.tokenize(word) # Tokenize the word to handle sub-tokens\n",
    "    for i in range(len(all_tokens) - len(word_tokens) + 1):\n",
    "        if all_tokens[i:i+len(word_tokens)] == word_tokens:\n",
    "            return list(range(i, i+len(word_tokens)))\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce4ddc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embeddings(model_name):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name)\n",
    "    model.eval()\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    top_words_list = []\n",
    "    embeddings_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    for sentence, sentence_metaphors in tqdm(zip(sentences, metaphors), total=len(sentences), desc=\"Encoding\"):\n",
    "        words = set(re.findall(r\"\\w+\", sentence.lower()))\n",
    "        if words & top_words:\n",
    "            encoded = tokenizer(sentence, return_tensors=\"pt\", truncation=True)\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**encoded.to(device))\n",
    "                hidden_states = outputs.last_hidden_state.squeeze(0) # [n_tokens, hidden_dim]\n",
    "\n",
    "            all_tokens = tokenizer.convert_ids_to_tokens(encoded[\"input_ids\"].squeeze(0))\n",
    "\n",
    "            for word in top_words:\n",
    "                token_idxs = get_token_indices(word, all_tokens, tokenizer)\n",
    "                if token_idxs:\n",
    "                    embedding = hidden_states[token_idxs].mean(dim=0).cpu() # Sub-token embeddings mean\n",
    "                    label = 1 if word in sentence_metaphors else 0\n",
    "                    top_words_list.append(word)\n",
    "                    embeddings_list.append(embedding.numpy())\n",
    "                    labels_list.append(label)\n",
    "\n",
    "    out_path = \"top_words_embeddings.npz\"\n",
    "    np.savez(out_path, words=top_words_list, embeddings=embeddings_list, labels=labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7bcbc678",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 16202/16202 [02:19<00:00, 116.25it/s]\n"
     ]
    }
   ],
   "source": [
    "model_name = \"bert-base-uncased\"\n",
    "embeddings(model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
